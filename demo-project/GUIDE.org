#+TITLE: Demo project development guide
#+PROPERTY: header-args:elisp :results silent

* COMMENT Document maintainance (not presented)
** COMMENT Remove all results
#+BEGIN_SRC elisp 
(org-babel-remove-result-one-or-many t)
#+END_SRC


* Introduction
Let's take a tour through our =demo-project=, looking at both the API and the spring boot internals.

* API
** Saying hello
The application exposes a REST API on port 8080 when run. Let's first investigate the root.

#+BEGIN_SRC restclient
GET http://localhost:8080
#+END_SRC

** Listing objects
Well, nothing is deployed on the root. Let's see if we can list objects instead.

#+BEGIN_SRC restclient
GET http://localhost:8080/values
#+END_SRC

#+RESULTS:
#+BEGIN_SRC js
[
  {
    "key": "foo",
    "value": "newvalue",
    "id": 1
  },
  {
    "key": "foo",
    "value": "bar",
    "id": 2
  },
  {
    "key": "foo",
    "value": "bar",
    "id": 3
  },
  {
    "key": "foo",
    "value": "bar",
    "id": 4
  }
]
// GET http://localhost:8080/values
// HTTP/1.1 200 
// Content-Type: application/json
// Transfer-Encoding: chunked
// Date: Wed, 12 May 2021 11:39:40 GMT
// Keep-Alive: timeout=60
// Connection: keep-alive
// Request duration: 0.299785s
#+END_SRC

** Creating an object
We can create an object by sending a =POST= request with some JSON.
#+BEGIN_SRC restclient
POST http://localhost:8080/values
Content-Type: application/json

{
  "key": "foo",
  "value": "bar",
}
#+END_SRC

#+RESULTS:
#+BEGIN_SRC js
{
  "key": "foo",
  "value": "bar",
  "id": 3
}
// POST http://localhost:8080/values
// HTTP/1.1 201 
// Location: http://localhost:8080/values/3
// Content-Type: application/json
// Transfer-Encoding: chunked
// Date: Wed, 12 May 2021 10:38:08 GMT
// Keep-Alive: timeout=60
// Connection: keep-alive
// Request duration: 0.189889s
#+END_SRC
*** ID is created by the service
When using  =POST= to create, we can't pick our own ID:
We can create an object by sending a =POST= request with some JSON.
#+BEGIN_SRC restclient
POST http://localhost:8080/values
Content-Type: application/json

{
  "key": "foo",
  "value": "bar",
  "id": 1
}
#+END_SRC

#+RESULTS:
#+BEGIN_SRC js
{
  "key": "foo",
  "value": "bar",
  "id": 4
}
// POST http://localhost:8080/values
// HTTP/1.1 201 
// Location: http://localhost:8080/values/4
// Content-Type: application/json
// Transfer-Encoding: chunked
// Date: Wed, 12 May 2021 10:39:35 GMT
// Keep-Alive: timeout=60
// Connection: keep-alive
// Request duration: 0.016180s
#+END_SRC

** Updating an object
In case we change out mind, we can =PUT= an update to the object, on the URI we got back for its creation (in the =Location= header).

#+BEGIN_SRC restclient
PUT http://localhost:8080/values/1
Content-Type: application/json

{
  "key": "foo",
  "value": "newvalue"
}
#+END_SRC

#+RESULTS:
#+BEGIN_SRC js
// PUT http://localhost:8080/values/1
// HTTP/1.1 204 
// Date: Wed, 12 May 2021 11:10:58 GMT
// Keep-Alive: timeout=60
// Connection: keep-alive
// Request duration: 0.167273s
#+END_SRC


* Asynchronous Java
** What is async and why?
*** Handling concurrency
- We expect very large, slow calls (but few of them)
  * e.g. a slow upload through a mobile network
  * Use =InputStream= and just slowly read (or =OutputStream= and slowly write)
  * Block a thread per request

- We expect very many simultaneous request, but small ones
  * e.g. distributing events to a great many consumers
  * Use asynchronous servlets (callbacks) or asyncronous Spring MVC (=CompletableFuture=)
  * Request thread is freed (while typically another does the work)

- We expect many simultaneous requests, and they're big and slow
  * Now what?
*** A bit of perspective
Latency comparison numbers

| Activity                           |      Nanoseconds |                        |
|------------------------------------+------------------+------------------------|
| L1 cache reference                 |           0.5 ns |                        |
| Branch mispredict                  |           5   ns |                        |
| L2 cache reference                 |           7   ns |                        |
| Mutex lock/unlock                  |          25   ns |                        |
| Main memory reference              |         100   ns |                        |
| Compress 1K bytes with Zippy       |       3,000   ns |                        |
| Context switch                     |      10,000   ns | (if working set in L2) |
| Send 1K bytes over 1 Gbps network  |      10,000   ns |                        |
| Context switch                     |    >100,000   ns | (bigger working set)   |
| Create a new thread in Java        |     100,000   ns |                        |
| Read 4K randomly from SSD*         |     150,000   ns |                        |
| Read 1 MB sequentially from memory |     250,000   ns |                        |
| Round trip within same datacenter  |     500,000   ns |                        |
| Read 1 MB sequentially from SSD*   |   1,000,000   ns |                        |
| Disk seek                          |  10,000,000   ns |                        |
| Read 1 MB sequentially from disk   |  20,000,000   ns |                        |
| Send packet CA->Netherlands->CA    | 150,000,000   ns |                        |
|------------------------------------+------------------+------------------------|
|                                    |              <r> |                        |

*** Threads are expensive
- Creating a new thread takes a long time
- Each thread eats >1MB of overhead (stack, housekeeping, ...)
- Scheduler has no insight to how /busy/ a thread is

- Keep working on the same data for as long as possible
** Callbacks
*** Don't call us, we'll call you
- Easy to grasp and understand
#+BEGIN_SRC jshell 
void makeHttpRequest(String url, Consumer<String> handleBody) {
    System.out.println("Pretending a request to " + url);
    handleBody.accept("Here's your body!");
}
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jshell
makeHttpRequest("http://test", body -> {
    for (int i = 0; i < 1; i++) {
        System.out.println("Got a results: " + body);
    };
});
#+END_SRC

#+RESULTS:
: Pretending a request to http://test
: Got a results: Here's your body!
*** A bit too simple?
- No guarantees which thread will invoke the callback
- Up the the implementer to handle locks
  * Did we talk about deadlock yet?

- Callback "hell"
#+BEGIN_SRC jshell
makeHttpRequest("http://test", body -> {
    writeDatabase(new Entry(body), onDone -> {
        sendRabbitMQMessage("We're getting there!", onAck -> {
            log.debug("Finally.");
        });
    });
});
#+END_SRC

** Future and CompletableFuture
*** History
- =Future= introduced to Java in [[https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Future.html][Java 7]]
  * Handle to an /asynchronous/ computation in progress (typically on a different thread)
  * Basically can only =.get()=, blocking the calling thread
  * Cancelling using =.cancel()= usually does nothing

- =CompletableFuture= added in [[https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html][Java 8]] 
  * Extends future with monadic operators
  * Although curious API choices: =.thenApply()= vs =.map()=, =thenCompose()= vs =.flatMap()=
*** CompletableFuture examples
Let's say we have a slow background computation
#+BEGIN_SRC jshell
CompletableFuture<Integer> compute(int input) {
    return CompletableFuture.supplyAsync(() -> {
        System.out.println("Starting computation for " + input);
        try { Thread.sleep(200); } catch (InterruptedException x) {}
        return input * input;
    });
}
#+END_SRC

#+RESULTS:

We can turn it into a string once the computation completes:

#+BEGIN_SRC jshell
CompletableFuture<String> willbe = compute(4).thenApply(i -> i.toString());
System.out.println("Printing now!");
System.out.println(willbe.get());
#+END_SRC

#+RESULTS:
: Starting computation for 4
: Printing now!
: 16
*** CompletableFuture examples
We can also wait on another computation, when the first one completes:
#+BEGIN_SRC jshell
CompletableFuture<Integer> composed = compute(4).thenCompose(i -> compute(i));
System.out.println(composed.get());
#+END_SRC

#+RESULTS:
: Starting computation for 4
: Starting computation for 16
: 256
*** Summary
- =CompletableFuture= is more expressive than callbacks
- Wacky API
- Complicated error handling (exceptions wrapped in =CompletionException=, because of cancellation that doesn't work)

- But, most importantly
  * Does this help with handling our big, slow, input, with many concurrent users?
** Reactive Streams
*** Reactive manifesto
- Developers realized that "one thread per request" and "exceptions" wasn't cutting it anymore
- 2016: The [[https://www.reactivemanifesto.org/][Reactive Manifesto]] (30k+ people). Reactive systems are:
  * /Responsive/
    + The system responds in a timely manner if at all possible.
  * /Resilient/
    + The system stays responsive in the face of failure. 
  * /Elastic/
    + The system stays responsive under varying workload. 
  * /Message Driven/
    + Reactive Systems rely on asynchronous message-passing to establish a boundary between components that ensures loose coupling, isolation and location transparency.
*** Reactive streams
- Reactive streaming concept developed several times separately
  * /rxJava/ (2014)
  * /Akka Streams/ (2015)
  * /Project Reactor/ (2015)
  * Many others
- Interoperability through =java.util.concurrent.Flow=
  * Low-level
*** Akka Streams
- Mature, large ecosystem
- Tight integration with other asynchronous concepts (e.g. actors)
- Tight integration with network I/O (streams of bytes)
- Well-[[https://doc.akka.io/docs/akka/current/stream/index.html][documented]] [[https://doc.akka.io/api/akka/current/akka/stream/javadsl/Source.html][API]]

- However, many concepts presented here also apply to other libraries
*** Akka Streams concepts

- =Graph= is a *blueprint* for a closed, finite network of *stages*, which communicate by streaming elements
- =GraphStage<S extends Shape>.= is one processing stage within a graph
  * taking elements in through zero or more *Inlets*
  * emitting through *Outlets*
- It's completely up to the stage when and how to respond to arriving elements
- All built-in graph stages embrace _backpressure_ and _bounded processing_

*** Akka graph stage types
- =Source<T, M>.= has one outlet of type =T=
- =Sink<T, M>.= has one inlet of type =T=
- =Flow<A, B, M>.= has one inlet of type =A= and one outlet of type =B=
- =RunnableGraph<M>.= has no inlets or outlets

*** Hello, streams
Let's do a hello world with some numbers:
#+BEGIN_SRC jshell
ActorSystem system = ActorSystem.create("QuickStart");
Materializer materializer = ActorMaterializer.create(system);

Source<Integer, NotUsed> numbers = Source.range(1, 3);

Sink<Integer, CompletionStage<Done>> print =
    Sink.foreach(i -> System.out.println(i));

CompletionStage<Done> done = numbers.runWith(print, materializer);

done.toCompletableFuture().get();
#+END_SRC

#+RESULTS:
: Done
: 1
: 2
: 3

*** Stream materialization

- _Graph_ is only a blueprint: nothing runs until it's given to a _materializer_, typically =ActorMaterializer=
- All graph stages are generic in their materialized type =M=
- Graph can be materialized more than once by calling =run()= or =runWith()=

#+BEGIN_SRC java
class Source<T, M> {
  // A graph which materializes into the M2 of the sink (ignoring source's M)
  public RunnableGraph<M2> to(Sink<T,M2> sink);

  // Materializes, and returns the M of the sink (ignoring this source's M)
  public <M2> M2 runWith(Sink<T, M2> sink, Materializer m) { ... }

  // A graph which materializes into the result of applying [combine] to
  // this source's M and the sink's M2
  public <M2, MR> RunnableGraph<MR> toMat(Sink<T,M2> sink,
                                          Function2<M,M2,MR> combine);
}

class RunnableGraph<M> {
  public M run(Materializer m);
}
#+END_SRC

*** Reusable pieces
- =Source=, =Sink= and =Flow= are all normal, immutable objects, so they're ideal to be constructed in reusable factory methods:
#+BEGIN_SRC jshell
public Sink<String, CompletionStage<IOResult>> lineSink(String filename) {
  Sink<ByteString, CompletionStage<IOResult>> file = FileIO.toPath(Paths.get(filename));

  return Flow.of(String.class)
    .map(s -> ByteString.fromString(s + "\n"))
    .toMat(file, Keep.right());
}
#+END_SRC

#+RESULTS:

Let's write our numbers to a file!
#+BEGIN_SRC jshell
numbers
  .map(i -> i.toString())
  .runWith(lineSink("/tmp/numbers.txt"), materializer).toCompletableFuture().get();
#+END_SRC

#+RESULTS:
: IOResult(6,Success(Done))

*** Time-based processing
#+BEGIN_SRC java
Source<Integer, NotUsed> numbers = Source.range(1, 100000000);

Sink<Integer, CompletionStage<Done>> print =
    Sink.foreach(i -> System.out.println(i));

CompletionStage<Done> done = numbers
    .throttle(1, Duration.create(1, TimeUnit.SECONDS), 1,
              ThrottleMode.shaping())
    .runWith(print, materializer);
#+END_SRC

- This does what you expect: print one message per second
- No =OutOfMemoryError=, akka buffers only as needed: /backpressure/
