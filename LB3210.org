#+TITLE: Microservices with Java and Spring Boot
#+PROPERTY: header-args:plantuml :exports results :var _dpi_="150" 
#+options: H:3
#+startup: beamer
#+LATEX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [8pt]
* Introduction
** Getting started
*** Schedule, day 1
|  Time | Duration | Activity                                                  |
|-------+----------+-----------------------------------------------------------|
| 13:00 |    00:10 | Welcome, Outline/Agenda                                   |
| 13:10 |    00:20 | Round table introductions                                 |
| 13:30 |    00:20 | What's a microservice                                     |
| 13:50 |    00:20 | Design for resilience                                     |
|-------+----------+-----------------------------------------------------------|
| 14:10 |    00:20 | Break(out) 1: Identify services & resilience (or lack of) |
|-------+----------+-----------------------------------------------------------|
| 14:30 |    00:15 | Round table identified services exchange                  |
| 14:45 |    00:45 | Infrastructure architecture                               |
|-------+----------+-----------------------------------------------------------|
| 15:30 |    00:20 | Break(out) 2: Checkout, install and run demo-project      |
|-------+----------+-----------------------------------------------------------|
| 15:50 |    00:30 | Data architecture                                         |
| 16:20 |    00:10 | Security architecture                                     |
| 16:30 |    00:30 | Software architecture                                     |
| 17:00 |    00:15 | GUIDE: Introduction, API, Metrics                         |
|-------+----------+-----------------------------------------------------------|
| 17:15 |    00:55 | Break(out) 3: Food (?), Extend demo-project with (???)    |
|-------+----------+-----------------------------------------------------------|
| 18:10 |    00:30 | Presentation(s) of extended demo project                  |
| 18:40 |    00:20 | Homework, Wrap-up, reserved time for extra subjects       |
|-------+----------+-----------------------------------------------------------|
#+TBLFM: @3$1..@>$1=@-1$2+@-1$1;U

*** Talk about yourself
- My Background
- What do I hope to get out of the course
- What's the smallest service I've ever written
** What's a microservice
*** Definition
- /Service/
  * One operating system process (often on its own server)
  * Exposes an API (sometimes also a UI)
- /Micro/
  * Theory: It's small
  * Practice: There are many
  * Independently deployable
*** Philosophy
- Business needs evolve
- Team composition changes
- Services should be disposable (design to be replaceable)
  * Rebuilt in 1-3 months
- Per service, use best technology matching experience and requirements 
*** Service scope
- Service belongs to one team
  * Team is responsible for entire service software life cycle
- Data store belongs to one service
- Independently deployable
*** Use cases 
- Embrace Conway's law: One system belongs to at most one team
- Monoliths are fine to start with
  * Time to market and technical debt vs. holistic design
- Strangler pattern
* Design for resilience
** Service failure
*** Your (or your colleague's) service will be down
P(everything working) = P(one service is working) ^ n_services

/Our service is up 99% of the time!/

Well, we have about 30 microservices, each with 3 copies. 
That means that 63% of the time, at least one service is down somewhere.
** Creating services
*** Guidelines
- Prefer sharded (partitioned) data stores over single points of failure
- Idempotency for all incoming data
- Always deploy more than 1 copy 
  * Investigate the need for a cluster-aware distributed framework
- Have a /Service dashboard/ with metrics
- Use =Bulkhead= to protect finite resources
*** Bulkhead
A single resource pool is covering multiple types of application requests

[[file:graphics/svg/without_bulkhead.png]]
*** Bulkhead in place
- Semaphore with an optional timed queue in front
- Other parts of the resource pool are still accessible

[[file:graphics/svg/with_bulkhead.png]]
** Consuming services
*** Guidelines
- Design for failure
  * Have methods/functions reflect doing I/O
  * Make time (and timeouts) explicit
  * Use =Circuit Breaker= where applicable
- Fail fast
  * =System.exit(1)= is a viable error handler
*** Circuit breaker
- Smart state machine towards 1 backend
  * /Closed/: Everything is working normally
  * /Open/: We've determined that the backend is down, and block requests
  * /Half-open/: We're allowing a few requests through, to test the waters

#+BEGIN_SRC plantuml :file graphics/circuit-breaker-state.png :hidden
skinparam dpi _dpi_
hide empty description
[*] --> Closed
Closed : passing requests through

Closed -> Open : [failure rate above threshold]
Open : blocking requests

Open -> Half_Open : [after wait duration]
Half_Open : pass some requests through to test availability

Half_Open -> Closed : [failure rate below threshold]
Half_Open -> Open : [failure rate above threshold]
#+END_SRC

#+RESULTS:
[[file:graphics/circuit-breaker-state.png]]
** Guidelines
*** Microservice pitfalls
- Service co-dependencies
  * Keep HTTP calls one way only
  * Plugin pattern
- Nested synchronous service calls
  * Added latency and failure possibility
  * Avoid these with event sourcing
  * Replicate data instead, or call asynchronously when possible
*** Need more inspiration?
- The twelve-factor app, [[https://12factor.net/][https://12factor.net/]]
- Provides sensible suggestions on a lot of topics
  * Port binding, dev/prod differences, admin processes
- Not the only way (geared towards ruby/python), but worth a thorough read
* Infrastructure architecture
** It's a linux world
*** Get familiar with linux
- Micro services are a linux world
- It's easier than ever to get started
  * WSL 2 (some integration, less "linux", and has [[https://www.polv.cc/post/2020/11/wsl-vs-virtualbox][issues]])
  * VirtualBox with e.g. Ubuntu (real linux)
  * Dual boot e.g. Ubuntu
  * Just get a Raspberry Pi
** Partitioned data stores
*** Partitioned data stores: introduction
- All data is split into partitions (also called /shards/), which are copied onto servers
- For each data element, a /key/ determines which partition it's stored on
#+BEGIN_SRC plantuml :file graphics/partitioned-data-stores.png :hidden
skinparam dpi _dpi_
skinparam linetype ortho

node n1 as "Server 1" {
  database b1 as "Partition B"
  database a1 as "Partition A"
}
node n2 as "Server 2" {
  database c2 as "Partition C"
  database b2 as "Partition B"
}
node n3 as "Server 3" {
  database c3 as "Partition C"
  database a3 as "Partition A"
}
n1 <-right-> n2
n2 <--> n3
n1 <--> n3

#+END_SRC

#+RESULTS:
[[file:graphics/partitioned-data-stores.png]]

*** Partitioned row stores
Each /row/ has a /key/ that specifies which partition(s) store data for that row. Data is typically stored in columns, following a schema.

- Open source: Cassandra
- Amazon: DynamoDB, Keyspaces
- Google: BigTable
- Azure: Cosmos DB (with Cassandra API)
*** Partitioned queues
Messages sent to a queue (sometimes called topic) are distributed to partitions, based on a /key/.
Messages typically small (some services have upper limit of 64kB).

- Open source: Kafka
- Amazon: SQS
- Google: Cloud Pub/Sub
- Azure: Storage Queue ( * ) , Service Bus ( * )

( * ) /not partitioned, size-limited/
*** Partitioned search
Full-text search is often important when dealing with data.

- Open source: Elasticsearch, SoLR
- Amazon: Hosted elasticsearch
- Google: Hosted elasticsearch
- Azure: Hosted elasticsearch
** Single-server data stores
*** Single-server data stores: introduction
- Many moving parts needed to make primary/replica failover work
  * PostgreSQL: Multiple servers possible, but failures leak to the client. =pgBouncer= as alternative.
  * MariaDB: Multiple servers possible with failover, fail-back is a manual process
  * RabbitMQ: Multiple servers possible with failover, but fail-back doesn't work in Spring ([[https://jira.spring.io/browse/AMQP-318][AMQP-318]]) 
- If you choose these, make failover testing part of your CI
*** RabbitMQ
- Message queue with focus on performance
- Original architecture single-server
  * Later extended with /Mirror Queues/ (primary/replica)
  * Extended with /Quorum Queues/ in 2019 (raft)
    + No message TTL, no message priorities
    + All cluster members have all data
    + All messages in memory! (in addition to storage)
*** RabbitMQ Data consistency
- AMQP "transaction"
  * Covers only a single queue
  * "Slow" (fsync for every transaction)
- /Publisher confirms/
  * Asynchronous message from RabbitMQ to client (after fsync): =basic.ack= or =basic.nack=
  * Impossible to predictably deal with lost broker connection (risk duplicate, risk lost messages)
- Manual /Consumer acknowledgement/
  * Consumer sends message to RabbitMQ to confirm handling of message is complete
  * =basic.ack=, =basic.nack(requeue)=, =basic.nack(no requeue)=
  * This is async, so no guarantee that the server receives it
    + Two generals agree
** Monitoring and alerting
*** Introduction
- Logging need not be a cross-cutting concern
  * Create monitored metrics instead
- Your service dashboard is as important as your public API
  * Have metrics on /everything/
  * Dashboard should be visible to and understandable by non-team members
- Be aware of your resource usage, check all environments at least daily
*** Protocol variations
- Push-based (statsd)
  * Application periodically (10 seconds) sends UDP packet(s) with metrics
  * Simple text-based wire format
  * Composes well if running with multiple metrics backends
  * Advantages: composability, easy to route, less moving parts
- Pull-based (prometheus)
  * Database calls into microservice periodically (10 seconds) over HTTP
  * Service needs to run extra HTTP server
  * Does not compose (multiple metrics backends need to be known on the prometheus side)
  * Advantages: less timing-sensitive
*** Metrics terminology
- Different frameworks use different terms
- [[https://micrometer.io/][Micrometer]] uses the following:
  * /Counter/ (sometimes called /event/): An occurrence of a discrete event
    + e.g. a request coming in
  * /Gauge/: The size of a single measurable quantity (and its unit)
    + e.g. the number of active TCP connections
  * /Timer/: The duration of an activity
    + e.g. the response time to a request
  * /Distribution summary/ (sometimes called /histogram/ or even /gauge/): Recorded values (and units) that go with events
    + e.g. the size of incoming requests in bytes
** Request tracing
*** TODO write about Jaeger and Zipkin
** Deployment
*** Virtualization and containerization
- First, there was plain hardware
- VM abstraction
  * Decoupling of multiple roles of one server
  * Memory and disk overhead
  * Linux optimizations (kernel shared memory)
- Linux can do many of this natively
  * /Namespaces/: Hide processes from each other
  * /Cgroups/: Limit resource usage
- Containers to make it fast and efficient
  * VM: GBs
  * Docker (ubuntu): 100's of MB
  * Docker (alpine): MBs
  * Instant startup
*** Docker
- Limited to linux in this course
- Lightweight layer over native cgroups isolation

- Dockerfile
#+BEGIN_SRC dockerfile
FROM node:12-alpine
RUN apk add --no-cache python g++ make
WORKDIR /app
COPY . .
RUN yarn install --production
CMD ["node", "src/index.js"]
#+END_SRC
  * Layers
  * Volumes
    + Handling of persistent data
  * Port mapping

- User mapping
- Don't run as root
*** Docker-compose
#+BEGIN_SRC yaml
version: '3.1'

services:

  db:
    image: postgres:13.2-alpine
    # Uncomment this to have the DB come up when you start docker / your laptop:
    #restart: always
    environment:
      POSTGRES_USER: demo
      POSTGRES_DB: demo
      POSTGRES_PASSWORD: example
    ports:
      - 5432:5432

  rabbitmq:
    image: rabbitmq:3.8.16-alpine
    # Uncomment this to have the DB come up when you start docker / your laptop:
    #restart: always
    ports:
      - 5672:5672    # AMQP
      - 15672:15672  # Web UI
#+END_SRC

- Groups several docker containers and storage
- Ideal for local testing
*** Kubernetes
- Manages a cluster of distributed docker containers with copies
  * /Pod/: Combination of one or more docker containers and their configuration
  * /Configmap/: Extra settings for pods, typically becoming a volume in the pod
  * /Deployment/: Automatic replicas and distributed upgrades for pods (and other resources)
- Ideal for production
- Configure Memory requests and limits
- Configure CPU requests
- Get comfortable getting thread and heap dumps
- Heap dump on out of memory (this /will/ happen)
  * =-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/dumps= to an =emptyDir= volume
** Configuration
*** Handling of externalized values
- Externalize "magic numbers" and strings
- Embrace your framework's ability to have /internal/ and /external/ configuration
  * /Internal/ (inside docker container) has defaults and values that don't really change
  * /External/ (mounted as a volume) has settings specific for that environment and/or server
- Changes to configuration files
  * Kubernetes: Configmap change does /not/ restart the pod
  * Hot reloading? Not in spring boot (watch file and shutdown instead)
- Environment variables for secrets: don't do it (leaking to docker, monitoring tools)
  * use files instead
- Environment variables for service injection: don't do it (ordering issues)
  * use dns instead (e.g. dns-java, akka discovery, [...])
** Load balancer
*** TODO write about kubernetes ingres (typically nginx)
*** TODO write about haproxy load balancer (tcp-level)
* Data architecture
** Domain-driven design
*** Introduction
- Software methodology
  * /Names in code must names used by the business/
- Popularized in 2003 by [[https://www.dddcommunity.org/book/evans_2003/][Eric Evans]] in his book
- Simple guideline lead to extremely useful patterns
- Useful example [[https://www.mirkosertic.de/blog/2013/04/domain-driven-design-example/][here]]
*** Bounded context
- Reasoning about complex business processes requires abstractions
  * A /domain model/ implements these abstractions as code
- Abstractions, and hence models, have a limited applicability
- /Bounded context/ makes this explicit
  * When creating a domain model, evaluate the scope of your design
  * Create sub-domains when you encounter them
  * Describe the bounds for your domain
*** Ubiquitous language 
- We have a domain model, great!
- Added value comes from day-to-day conversations
  * Among developers
  * Between developers and the customer
  * Between developers and the user
- Is everyone speaking the same language?

- /Ubiqutous language/: All team members use important terms in the same way
  * Within a bounded context
*** Event storming workshop
- We need to quickly learn a new domain
- /Business process modeling/ and /requirements gathering/
- Bring together /domain experts/ and /developers/

- Discover events that occur in the business, and what triggers them
  * /Business Event/, e.g. /a customer has applied for a loan/
  * /Command/, e.g. /create a new loan request/
  * /Actor/, e.g. /loan requester/
  * /Aggregate/, e.g. /Loan Application/

- Why do you think the focus is on /Events/, rather than /Aggregates/?
- Useful example [[https://www.rubiconred.com/blog/event-storming][here]]
** Other patterns
*** Command query responsibility segregation
- CQRS: Have two separate data models (and split your API accordingly)
  * A /command/ model, for API calls that only change data (and do not return data)
  * A /query/ model, for API calls that only return data (and do not change data)

- Builds on CQS (Command query separation). One method can only do one of two things:
  * Perform a /command/, by having side effects (and not returning a value)
  * Perform a /query/, returning a value (and not having side effects)

- We'll see CQS again
*** Event sourcing
- Traditional relational database: CRUD
  * Update in place
- Change log, shadow table

- Turn it upside down: /Event journal/ is the source of truth
  * Read from the event journal to create your query model
  * No more CRUD
  * Read from your event journal again: /full-text search!/
  * Read from your event journal again: /business analytics!/

- Event journal part of API?
** Data formats
*** XML
#+BEGIN_SRC xml
<?xml version="1.0" encoding="UTF-8"?>
<Invoice
 xmlns="urn:oasis:names:specification:ubl:schema:xsd:Invoice-2"
 xmlns:cac="urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2"
 xmlns:cbc="urn:oasis:names:specification:ubl:schema:xsd:CommonBasicComponents-2">
 <cbc:ID>42</cbc:ID>
 <cbc:IssueDate>2004-05-24</cbc:IssueDate>
 <cac:LegalMonetaryTotal>
  <cbc:PayableAmount currencyID="USD">52.00</cbc:PayableAmount>
 </cac:LegalMonetaryTotal>
</Invoice>
#+END_SRC

- Extensible Markup Language
- Composes very well
  * Namespaces prevent shadowing
  * Natural order of tags can be useful
- /De facto/ schema standard (XSD) has unfortunate limitations
  * Hard to express "order does not matter"
  * Hard to express "this schema can be extended with extra tags and attributes"
  * Alternatives: /schematron/ (alive) and /relax-ng/ (dead?)
- Still, a very sensible default choice
*** JSON
#+BEGIN_SRC js
{
  "invoice": {
    "id": "42",
    "issueDate": "2004-05-24",
    "legalMonetaryTotal": {
      "payableAmount": {
        "value": "52.00"
        "currencyID": "USD"
      }
    }
  }
}
#+END_SRC
- /JavaScript Object Notation/
- Started its life in the web browser (~2000)
  * XML inconvenient to deal with in Javascript back then (SAX API)
  * JSON could just be parsed as Javascript directly
- No namespaces
  * JSON is useless without context
- No (useful) types
  * JavaScript /number/ is a technically a double-precision float (even though in JSON it can contain unlimited digits)
  * Even [[https://json-schema.org/understanding-json-schema/reference/numeric.html][JSON schema]] does not remedy this
- No comments
*** Protobuf
#+BEGIN_SRC js
message SearchRequest {
  required string query = 1;
  optional int32 page_number = 2;
  optional int32 result_per_page = 3;
}
#+END_SRC

- Very compact binary format
- Started at Google, today >70 implementations
- Built with organic versioning in mind
- Ideal for storing events of event sourcing (if you have a lot of them)
*** Designing for extensibility
- Use schemes and code lists instead of fixed enumerations
- Use rich data objects instead of flat numeric values
  * e.g. =Amount=, =Measurement=, =GeoCoordinate=, =Quantity=
- Use namespaces and URIs where you can
* Security architecture
** Authentication patterns
*** User-to-service authentication
- I want code running on a user's computer to call me (let's assume web browser)
- OpenID Connect, simplified flow:
  1. /Resource owner/ wants /client/ to log on to /authorization server/
  2. Client is redirected to authorization server
  3. User verifies trust of authorization server and logs on
  4. Authorization server redirects client back (with authorization code)
  5. Client contacts resource owner with /code/
  6. Resource owner exchanges code for /token/
  7. Token can be used in =Authorization: Bearer= http header
*** Service-to-service authentication
- I want code running on other backend services to call me (outside of the context of a user)

- Mutual TLS
  * Server has a certificate, proving it's who it claims
    + Client has established trust on a root certificate, having signed the server certificate
  * Client has a certificate, proving it's who it claims
    + Server has established trust on a root certificate, having signed the client certificate

- In practice
  * Create (or purchase) a root certificate for your business, lock it tight
  * Create intermediate CAs for particular roles, e.g. for singing micro-services
  * Use /Certificate Signing Requests/ to reflect real business flow
  * For your service clients
    + Have server sign client certificates directly
    + Or, delegate to an intermediate CA, and implement whitelisting
- Confirm that OCSP (/Online Certificate Status Protocol/) can be used to revoke certificates
** Implementation
*** Authorization checks
- Prefer to keep internal to service
- Replicate user memberships through event sourcing
- Synchronous calls least favorable choice
* Software architecture
** Spring Boot
*** About Spring Boot
- /Spring/: Framework providing useful abstractions for common concepts
  * Dependency injection of (mostly) singletons
  * Transaction management
  * Asynchronous messaging
  * Many, many more

- /Spring boot/: Automatically wire default singletons for various other libraries
  * Kafka
  * RabbitMQ
  * Flyway
  * JOOQ

- Sensible defaults, or magic mystery?
** Useful modern Java features
*** Lambdas (Java 8+)
- A /lambda/ is an anonymous function body
- You can write them anywhere a /Functional Interface/ is expected, e.g.
#+BEGIN_SRC java  :classname LambdaDemo
public class LambdaDemo {
    interface MathOp {
        public int apply(int input);
    }

    static int twice(int input, MathOp op) {
        return op.apply(op.apply(input));
    }

    public static void main(String[] args) {
        int result = twice(10, i -> i + 1);
        System.out.println(result);
    }
}
#+END_SRC

#+RESULTS:
: 12
*** Function types (Java 8+)
- For use with lambdas, Java added a few /Functional Interfaces/ in [[https://docs.oracle.com/javase/8/docs/api/java/util/function/package-summary.html][java.util.function]]
#+BEGIN_SRC java
package java.util.function;

interface Function<T,R> {
    R apply(T t);
}

interface Supplier<T> {
    T get();
}

interface Consumer<T> {
    void accept(T t);
}

interface BiFunction<T,U,R> {
    R apply(T t, U u);
}
#+END_SRC

*** Type-inferred variables (Java 11+)
- Local variables now no longer need a type
- This is especially useful with long generic types
- =var= should be your default in new code

#+BEGIN_SRC java  :classname TypeInferred
import java.util.function.Function;

public class TypeInferred {

    static <T> Function<T,T> twice(Function<T,T> fun) {
        return t -> fun.apply(fun.apply(t));
    }
    
    public static void main(String[] args) {
        var twiceAddOne = twice((Integer i) -> i + 1);
        int result = twiceAddOne.apply(10);
        System.out.println(result);
    }
}
#+END_SRC

#+RESULTS:
: 12

*** Records (Java 14+)

#+BEGIN_SRC java  :classname Rectangle :results scalar
public record Rectangle(float length, float width) {
    public Rectangle {
        System.out.println("This is a compact constructor.");
    }

    public static void main(String[] args) {
        var r = new Rectangle(5, 3);
        System.out.println(r);
    }
}
#+END_SRC

#+RESULTS:
: This is a compact constructor.
: Rectangle[length=5.0, width=3.0]

- A =record= is an immutable value type
  * Each argument is a private, final field
  * Getter for each argument with the same name
  * Constructor with all arguments (can have extra code as shown)
  * Appropriate =equals=, =hashCode= and =toString=

- Ideal for data classes, and perhaps domain model
- Expect JSON and XML code generators to pick these up
  * JOOQ was [[https://github.com/jOOQ/jOOQ/issues/10287][recently]] updated with =record= support for POJOs (for 3.15.0)
** Relational databases
*** Migration management
- Relational databases change, just like code

- Change management processes in the wild
  * Schema changes just aren't allowed
  * Schema changes require a paper form, a DBA to sign off, and a 6-month process
  * Schema changes are done manually, live, on the production database, by a junior dev

- Manage your migrations: =Flyway=
  * Write incremental changes as scripts
  * Trace script execution in the database itself
  * See an [[file:demo-project/src/main/resources/flyway/migrations/V1__createdb.sql][example]]
*** Interacting with data
- Several layers of abstraction
  * Direct JDBC
  * Spring =JdbcTemplate=: Thin wrapper, helps with resource clean-up
  * Spring data (/JDBC/ or /JPA/ variants): Automates mapping to/from Java objects
  * JOOQ: Compiles code from your database schema

- Remember databases are allowed to change?
  * Let's use the compiler to our advantage
*** Introducing JOOQ
Given the following table:
#+BEGIN_SRC sql
CREATE TABLE entry (
  id SERIAL PRIMARY KEY,
  key VARCHAR(64),
  value VARCHAR(255)
);
#+END_SRC

JOOQ will allow you to write code like:

#+BEGIN_SRC java
ctx.selectFrom(ENTRY).orderBy(ENTRY.ID).fetchInto(Entry.class)
#+END_SRC

- Type-safe table and column definitions
- Automatic mapping into generated class
- Compile errors when you remove/change columns in your schema
** RabbitMQ
*** Spring Boot RabbitMQ
- Just adding the maven dependency is enough
#+BEGIN_SRC xml
<dependency>
  <groupId>org.springframework.amqp</groupId>
  <artifactId>spring-rabbit</artifactId>
</dependency>
#+END_SRC

- Will look for rabbitMQ locally on the default port
- Can't fail application if RabbitMQ is/goes down
*** Spring Boot: Read from queue
- We use (surprise!) an annotation to read from a queue
#+BEGIN_SRC java
@Component
public class MyComponent {
    @RabbitListener(queues = "demoQueue")
    public void handle(String message) {
        // ...
    }
}
#+END_SRC
- Spring will send a consumer =ack= when, and if, method returns normally
- Exceptions will cause a =nack= with redelivery (except for some specific cases)
*** Spring boot: Send to queue
- Using /Publisher Confirms/ is not the default (or easy) in Spring Boot
  * "Fire and forget" is the default

- Enable in configuration
#+BEGIN_SRC conf
spring.rabbitmq.publisher-confirm-type=simple
#+END_SRC

- Wrap your message sending code in a lambda
#+BEGIN_SRC java
template.invoke(cb -> {
    cb.convertAndSend("demoQueue", message);

    // Potentially we can do other things in between sending the message and awaiting
    // its conformation.

    cb.waitForConfirmsOrDie(1000);
});
#+END_SRC
** Functional programming
*** Lambdas as control constructs
- Lambdas are ideal to cover large code blocks
- Let's create a simple transaction manager
#+BEGIN_SRC java
class Transactional {
    public <T> T inTransaction(Function<Connection,T> fun) {
        var conn = DriverManager.getConnection(url);
        conn.setAutoCommit(false);
        try {
            fun.apply(conn);
            conn.commit();
        } catch (Exception x) {
            conn.rollback();
        } finally {
            conn.close();
        }
    }
}
#+END_SRC
*** Lambdas as control constructs (contd.)
- Now we can wrap a lambda and get a transaction around the block
#+BEGIN_SRC java
void updateUser(String name, String pet) {
    inTransaction(conn -> {
        validatePetName(conn, pet);

        var stmt = conn.prepareStatement("UPDATE users SET name=?, pet=?");
        stmt.setString(1, name);
        stmt.setString(2, pet);
        stmt.executeUpdate();
        stmt.close();
    });
}
#+END_SRC

*** Pure functions
- Remember CQS (Command query separation)
- A /Pure function/ will
  * Given the same arguments, will always return the same value
  * Not have any side effects (I/O, global state)
- Pure functions are great!
  * Trivial to test
  * Compose really well
  * Easy to reason about
*** Immutability
- Let's have a look at this pure function
#+BEGIN_SRC java
int calculateAverage(List<Integer> items) {
   // ...
}
#+END_SRC

Is this a pure function?
*** Immutability (cont.)
- Well, here's an implementation
#+BEGIN_SRC java
int calculateAverage(List<Integer> items) {
   items.clear();
   items.add(42);
   return 42;
}
#+END_SRC

- To reason about pure functions, we need immutable data structures
  * Lists that can not be modified
  * Maps as well, and many others
- We still want to create modified copies (of course)
*** I don't need immutability!
- There are many other good use cases for immutable data structures
  * Caches
  * Callback APIs
  * Parallel processing
  * Messaging
*** VAVR
- Library for Java 8+ for functional programming and immutability
- As an example, let's look at [[https://www.javadoc.io/doc/io.vavr/vavr/latest/io/vavr/collection/List.html][io.vavr.collection.List]]
#+BEGIN_SRC java
import io.vavr.collection.*;

List<Integer> list1 = List.of(1, 2, 3);

// Create a new list with more values:
List<Integer> larger = list1.append(4).append(5);

// Let's turn all integers to strings
List<String> strings = larger.map(i => i.toString());
#+END_SRC
- Other useful types from =io.vavr.collection=:
  * =Vector<T>;= (an immutable /hash trie/, with efficient inserting and removing)
  * =HashMap<K,V>;= (an immutable hash map)

- Useful control data structures in =io.vavr.control=:
  * =Option<T>;= (single-valued element, which can either be =None= or =Some(value)=)
    + This is the preferred way of handling potentially-absent values
  * =Either<L,R>;= (single-valued element, which can either be =Left(leftValue)= or =Right(rightValue)= )
    + This is the preferred way of handling values (R) that may have failed with an error (L)
*** Null-free style
- =NullPointerException= is hiding in every =.= in traditional java

- There's no need to use =null= anymore to carry semantic value in new applications
  * In plain JDK, there's =java.util.Optional=
  * For more integration with collections, there's VAVR

- =@NotNull= ?

- Simple rule: the word =null= must not occur in your source code
  * Exception: integration with libraries that expect =null=

- =Option= (or =Optional=) is fine both for method arguments, return types, and fields
  * However, consider method overloading as well
** Annotation vs. functional style
*** Composing Spring annotations
- Let's listen from a message on RabbitMQ
#+BEGIN_SRC java
@RabbitListener(queues = "demoQueue")
@Transactional
@Timed("demoQueue.message")
public void handleMessageFromRabbit(String message) {
    System.out.println("We've got a message!");
}
#+END_SRC

- Well, we can see that Spring sprinkles magic on this method which
  * Invokes it when a message arrives on RabbitMQ
  * Wraps it in a database transaction
  * Measures how long it takes

- But, in what order?

- And, what code implements these concerns?
*** Composing lambdas
- Let's look at this alternative method implementation
#+BEGIN_SRC java
@RabbitListener(queues = "demoQueue")
public void handleMessageFromRabbit(String message) {
    transactions.doInTransaction(ctx -> {
        myCustomMetric.measureTime(-> {
            System.out.println("We've got a message!");
        });
    });
}
#+END_SRC

- We keep the =@RabbitListener= (for now, ask us about streams!)
- Other concerns' ordering is trivial to follow
- Implementation is trivial to find
*** Functional style
- Java libraries are starting to use lambdas as defaults over annotations
  - Resilience4J uses lambdas to wrap circuit breaker, bulkhead
  - JOOQ uses lambdas to demarcate transactions
- Advantages
  * Discoverability, Composability, Testability
- Sneak peak into lambdas for handling HTTP ([[https://doc.akka.io/docs/akka-http/current/routing-dsl/routes.html][akka-http]]):
#+BEGIN_SRC java
Route route = path("users", () ->
    concat(
        get(() ->
            complete("Here could be a list of users!")
        ),
        post(() ->
            entity(Jackson.unmarshaller(User.class), user ->
                onSuccess(addUser(job), r -> complete("User added!"))
            )
        )
    )
);
#+END_SRC

** TODO Streams
- Java streams is not it
- Use slides of future vs. callbacks vs. streams
- Akka streams very mature, show RabbitMQ example
* Wrapping up today
** Let's do another round
*** Please share
- This I already knew
- This I learned today
* Start of day 2
** Getting started
*** Schedule, Day 2
|  Time | Duration | Activity                                     |
|-------+----------+----------------------------------------------|
| 13:00 |    00:10 | Welcome, Outline/Agenda                      |
| 13:10 |    00:40 | Homework presentations (6 teams, 5 min each) |
| 13:50 |    00:10 | Recap of day 1                               |
|-------+----------+----------------------------------------------|
| 14:00 |    00:05 | Break                                        |
|-------+----------+----------------------------------------------|
| 14:05 |    00:30 | Strategy and team dynamics                   |
| 14:35 |    00:30 | Getting your service used                    |
| 15:05 |          |                                              |
#+TBLFM: @3$1..@>$1=@-1$2+@-1$1;U


* Micro service life cycle
** Dependency management
*** Developing a new service
- I want to write a new micro service! 
  * I need a database, a queue, the filesystem for some caching
  * Oh, and I'm talking to twitters API, and our home-grown analytics API

- How do I deal with these dependencies during day-to-day development?
  * "Leaf" dependencies: often OK to run directly (e.g. data stores)
  * "Node" dependencies (other microservices): often have dependencies of their own
    + You know its API, right?
    + Mock it! Wiremock, or any simple http server

*** Running dependencies
  * Maintain a =docker-compose= file for your project
    + Real dependencies: they're probably on =docker-hub= already
    + Mocks: use the =build= feature if needed
  * New developers can get started instantly

** Extending a service
*** Developing a new feature
- Don't hide your new feature on a branch
- Release early and often
  * But only activate it in certain environments and/or users
- Feature flag
- A/B testing
** Testing
*** Introducing bugs
- Rate of bugs introduced into systems are a function of
  * Developer experience
  * Development environment (physical and technological)
  * Methodology

*** Finding bugs
- Fixing bugs is more expensive, the later they are found
  * While writing code: just think of different solution
  * While code is in review: communication, context switch, and the above
  * While code is in user testing: (much) more communication, context switch, and all the above
  * After code is released: (even) more communication, impact analysis in data, and all the above

*** Preventing bugs
- Test at different layers
  * On code itself: Pair programming
  * On one unit (e.g. class): /Unit tests/. Run in seconds.
  * On one service (e.g. rest API): /Component tests/. Run in tens of seconds.
  * On a suite of services (e.g. UI): /End-to-end tests/. Run in minutes.
  * On your entire infrastructure: /Smoke tests/. Run periodically, on production, with external dependencies
** Deployment
*** Getting your service out there
    "/All software has a test environment. Some software is lucky to have a separate production environment as well."/
        - unknown
*** Doing deployments
- Automate the environments themselves (=terraform=, =vagrant=, ...)
- All deployments to all environments must be automated
- It's OK to have gatekeepers, e.g.
  * After a PR is merged, automatic deploys are done to =dev= and =test= environments
  * The =prod= environment requires a manual button press
- Forward deploy only
  * Rollbacks are a pain
  * Your next deploy is only minutes away
  * Emergencies should be rare (testing, early release, multiple environments)
* Strategy and team dynamics
** Succeeding with microservices
*** Microservices and agile
- Embrace change
- Team visibility
- Stakeholder support
- Team(s) in same time zone as stakeholders (which includes users)
  * Distributed users? distributed team!
*** Migrating your monolith
- Chainsaw anti-pattern
- Strangler pattern
- Maven modules
*** Do we need a separate dev/ops team? (no)
- Automate everything (rolling production deploy)
- Deploy in the morning, monitor your dashboards
- However, "infra tooling" or "platform" team can be helpful
- The same holds for the "DBA" team
* A selection of REST patterns
** Resource tags and caching
*** Resources have versions
- Servers can include an =ETag=, which specifies which /version/ of a resource is being served
#+BEGIN_SRC restclient
GET http://example.com/widgets/15

200 OK
Content-Type: application/json
ETag: "524"
#+END_SRC
- No guarantees are made about the content of =ETag=, but often APIs will document what it represents, e.g.
  * A timestamp of some sort
  * A monotonically-increasing number
  * A hash of the latest content
*** Conditionally retrieving a resource
- If the latest =ETag= we have seen is "524", we can poll for changes
- The =If-None-Match= header will /only/ execute our request if the =ETag= has changed
#+BEGIN_SRC restclient
GET http://example.com/widgets/15
If-None-Match: 524

304 Not Modified
#+END_SRC
- The server will not send any response if the resource is still at this version
*** Optimistic offline lock
- The =ETag= is also useful to make sure nobody else has edited a resource that we're writing back
- The =If-Match= header will /only/ execute our request if the =ETag= matches
#+BEGIN_SRC restclient
PUT http://example.com/widgets/15
If-Match: 12345
Content-Type: application/json

{ /* ... some content ..* }

412 Precondition Failed
#+END_SRC
*** Resources can be modified
- Servers can include a =Last-Modified= tag, which specifies /when/ a resource was last changed
- This can be useful in addition to an =ETag= tag
#+BEGIN_SRC restclient
GET http://example.com/widgets/15

200 OK
Content-Type: application/json
ETag: "524"
Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT
#+END_SRC
- Request header exist that perform checks against the last-modified date, like =ETag=:
  * =If-Modified-Since= executes the request /only/ if the last-modified is past the given date
  * =If-Unmodified-Since= executes the request /only/ if the last-modified is at most the given date
*** Preventing caching
- For service-to-service REST calls, we generally don't worry about caching
- For web browsers, we often want to disallow caching of REST responses
  * Include =Cache-Control: no-cache=
** Content-type negotiation
*** Resource representation
- The same REST URI is allowed to have several representations
  * XML, JSON or Protobuf
  * Short or long
  * Version 1 or version 2
*** Specifying resource representation
- The server specifies the representation of a resource
  * The =Content-Type= resource header
- This is typically a well-known value
  * =text/xml=
  * =application/json=
  * =application/protobuf=
- But it doesn't have to be
  * =application/vnd.example.myresource.v1+json=
  * =application/vnd.example.myresource.v2+json=
  * =application/vnd.example.myresource.short+json=
  * =application/vnd.example.myresource.long+json=
*** Requesting a resource type
- The client sends an =Accept= header with the representations it wants/understands
- In case of a single representation:
#+BEGIN_SRC restclient
GET http://localhost/myresource
Accept: application/json
#+END_SRC
- In case multiple representations are alright (order has no semantic meaning):
#+BEGIN_SRC restclient
GET http://localhost/myresource
Accept: application/json, text/xml
#+END_SRC
- Multiple representations are alright, but preference for xml:
#+BEGIN_SRC restclient
GET http://localhost/myresource
Accept: application/json;q=0.9, text/xml
#+END_SRC
*** Serving resource alternatives
- Content-type negotiation is complex to implement
- How easy it is to support depends on your framework
  * /Spring Boot/ has many different ways to manage resource representation
    + Look into =HttpMessageConverter=, so you can take control
  * Others, e.g. =akka-http= has a marshaling infrastructure that directly models content-type negotiation
** Asynchronous and long-running processes
*** Case: REST API to represent workflow instances
- Start a new workflow
- See which human is working on the case
- Quickly resume if system is working on the case
*** REST is about resources
- For slow-running processes, make the process itself a resource, e.g.
  * =/workflows/=
  * =/transactions/=
  * =/cases/=
- You can now reason about individual processes
  * Query state, affect them, delete them, see changes
*** Observing change on one resource
- Tell client to periodically poll
  * Use =If-None-Match= for early exit
  * Use heavy caching on the server-side to reply to polls as early as possible
*** Observing change on a set of resources
- Build your system using /Event Sourcing/
- Expose your event journal (or a light, or filtered version) as a REST resource
  * This can be done regardless of storage (JDBC, Cassandra, Kafka)
- Various candidates for the data format
  * Plain
#+BEGIN_SRC restclient
GET http://localhost/journal/events?since=Wed+May+26+11:59:05+2021+UTC&limit=50
Accept: application/json
#+END_SRC
  * Hanging GET
#+BEGIN_SRC restclient
GET http://localhost/journal/events?since=Wed+May+26+11:59:05+2021+UTC&limit=50&maxwait=60000
Accept: application/json
#+END_SRC
  * Server-sent events ([[https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events][SSE]])
#+BEGIN_SRC restclient
GET http://localhost/journal/events?since=Wed+May+26+11:59:05+2021+UTC
Accept: text/event-stream
#+END_SRC
  * Web sockets
#+BEGIN_SRC restclient
GET http://localhost/journal/events?since=Wed+May+26+11:59:05+2021+UTC
Connection: Upgrade
Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13

HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=
Sec-WebSocket-Protocol: chat
#+END_SRC
** Multi-dimensional versioning
*** Semantic versioning in REST
- Often used for library dependencies and packaged software releases
- Version number has three parts (/major/, /minor/, /patch/): version =2.0.15=
  * A new release always must have a new version
  * If a release has no new functionality (only bugfixes), increase the /patch/
  * If a release has new functionality that doesn't break API promises, increase the /minor/
  * If a release has new breaking functionality, increase the /major/
- How does this relate to REST?
*** Semantic versioning in REST (cont.)
- How does this relate to REST?
  * It doesn't!
  * REST is a call to a remote system
    + Could be deploying new versions multiple times per day
  * The whole point is the client /doesn't/ want (or need) to see those

- OK, what do we do instead?
  * Version across all HTTP dimensions
*** Versioning in body structure
- Many extensions fit fine into existing body structure
  * Adding of fields
  * Adding of values to enumerations or code lists
- If DDD has done its work, terminology should mostly hold
*** Versioning in content type
- If a breaking change is needed
- It might be limited to only one content type
- Client requests old version:
#+BEGIN_SRC restclient
GET http://localhost/myresource
Accept: application/vnd.example.myresource.v1+json
#+END_SRC
- Client requests new version:
#+BEGIN_SRC restclient
GET http://localhost/myresource
Accept: application/vnd.example.myresource.v2+json
#+END_SRC
*** Versioning in query parameters
- Don't do this
  * Query parameters affect /which/ and /what/ resource(s) are returned, not /how/
- The meaning of query parameters may themselves be versioned
*** Versioning in path
#+BEGIN_SRC restclient
GET http://localhost/service/versions/1/myresource
#+END_SRC
- Often used as first choice
- Should be your last resort:
  * Your path is the name of your resource
  * Your DDD workshop (probably) didn't event storm about "versions"
  * Your system (probably) doesn't have 2 complete implementations
  * This does often not reflect reality
*** Versioning using custom headers
- Client sends a custom header of the API version they've implemented against
- Server sends a custom header of the API version that's current
- This does kinda work

- Fairly weak way to work around /actually/ dealing with semantic changes and compatibility
* Getting your service used
** Public API 
*** An API is an interface
- /Application Programming Interface/
  * It's how external components affect what our service does
  * Better lay down some rules
- But our service is only used by our team, we don't need documentation!
- Ideal for test-first development
- Where do I put my private API?
*** Example API
- Let's look at an [[file:demo-project/documentation/demo-api.html][example API]] example API together
  * Its [[file:demo-project/documentation/demo-api.raml][RAML source]] is available
- Semantic format for describing REST APIs: RAML, OpenAPI
  * RAML: YAML-based, more advanced, easier to write by hand
  * OpenAPI: JSON-based, more tooling support
*** Content-type negotiation
- Embrace content-type negotiation (XML /and/ JSON, not XML /or/ JSON)
- XML API:
  * Do create XSD for your data types, but communicate how it should be interpreted
  * Do you reserve the right to add new tags and attributes?
- JSON API:
  * Create JSON schemas for everything
  * In addition, verbosely describe all numeric types and their intended usage

** Public developer guide
*** But I've written the documentation!
- Just a list of endpoints may not be enough for some developers
- Lot of context and assumed knowledge
  * Ubiquitous language may not extend to all new API users
  * Lack of experience with JSON, XML, HTTP headers
*** Different people, different learning styles
- Write a developer guide that describes typical scenarios from a user's perspective
  * How to get started (e.g. get an SSL certificate)
  * How to list widgets in XML or JSON
  * How to create a new widget
- There's no shame in taking an English technical writing course
- Pick tooling that suits your way of working (e.g. =HTTPie=, =org-mode= with =org-babel=, ...)
** Public service dashboard
*** Priorities!
- What's the first thing you do when you get to your office?

- Users will be curious about your service status
  * If your users are internal, give them access to the actual dashboard
  * In fact, consider giving them access to your source code and issue tracker as well
*** Designing your dashboard
- Your dashboard should be showing
  * System metrics (load average, disk space, CPU usage, memory usage, network I/O, disk I/O)
  * Your process' metrics (CPU usage, memory usage)
  * Your JVM's metrics (Heap committed, heap used, GC time, thread count, log4j count)
  * Your framework's metrics (HTTP server open connections, HTTP client open connections, response times, response errors)
  * Your business metrics (number of pets signed up, total invoice amount, size of received chat messages)

- For each environment, after a few days examine the graphs
  * Establish a baseline, and create an alert for /each/ metric
* Assignments
** Assignment A
- Target: individual developer, or developers that have worked on the same monolith.
*** Part one: architectural description [4 hours]
- Pick a recent project where you have worked on a /monolith/. The bigger the better.
- Create a (rough) sketch that depicts the monolith the most important other systems it communicates with
  * Include both clients and dependencies
  * Include data stores and queues
  * Include cloud-based services
  * For each interface, describe (generally) which protocol or format is used, how often it's used, and the size of messages
- Create a (rough) sketch that depicts the monolith, its internal structure, and the team(s) changing those parts
  * Try to include the size of teams and how often they perform changes
- Create a (rough) timeline that shows how a typical new feature finds its way from inception to being in production
  * Include testing in various contexts, customer meetings, and other forms of feedback
*** Part two: microservice design
- Using the techniques from this course, draw a set of candidate microservices that can take over part(s) of the monolith
- 
** Assignment B
- Target: individual developer, or developers that have been on a green-field project together.
*** Part one: architectural description [1 hour]
*** Part two: non-functional extensions

** Assignment: Extend demo project
*** To be designed
- Change configuration to YAML
- Try to run application from a docker container
- Add a domain model (as per DDD) to the demo-project

*** Other assignment ideas
- Take your service, and see how testing works. Are you missing layers? how many tests of each do you have?

* Interesting links
https://world.hey.com/joaoqalves/disasters-i-ve-seen-in-a-microservices-world-a9137a51
https://copyconstruct.medium.com/testing-in-production-the-safe-way-18ca102d0ef1

* Notes
- Export both to beamer and plain PDF
- Test with external monitor
- Extra topics
  - REST patterns:
    + Async vs. Sync on rest, long-running sagas, websockets, SSE, long polling with client-specified timeout
    + Content-type negotiation (xml, json, versions)
    + Versioning across dimensions
    + Resource tags, if-modified-since, and caching
  - Streaming in-depth with Akka and Akka-http
- Practice inkscape freehand drawing and shortcuts
- Light theme
- Example DDD class diagram

- Pure function example
